# ------------------------------
# General NN training configs
# ------------------------------

# to use torch.cuda.amp
amp: false

# will be equally divided by number of GPUs if in distributed
batch_size: 2

# epoch_length of ignite.Engine.run() [int, float]
# if float, round(epoch_length * len(dataloader))
# if int, epoch_length
epoch_length_train: 1.0
epoch_length_eval: 1.0

# num_workers for DataLoader
j: 0

# max_epochs of ignite.Engine.run()
max_epochs: 2

# learning rate used by torch.optim.*
lr: 1e-3

# logging interval of training iteration
log_train: 50

# logging interval of evaluation epoch
log_eval: 1

# try overfitting the model
overfit_batches: 0

# datasets path
path: null

# plot the transformed image
save_plot_img: false

# sanity checking the evaluation first in batches
sanity_check: 2

# used in ignite.utils.manual_seed()
seed: 666

# to use wandb or not for logging
wandb: false

defaults:
  - net: null
  - override hydra/job_logging: minimal

# -----------------------
# Distributed configs
# -----------------------

# The number of processes to launch on each node, for GPU training
# this is recommended to be set to the number of GPUs in your system
# so that each process can be bound to a single GPU
nproc_per_node: null

# The number of nodes to use for distributed training
nnodes: null

# The rank of the node for multi-node distributed training
node_rank: null
